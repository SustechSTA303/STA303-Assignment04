{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58bc3b2f-26f4-476d-ad84-39d7b760dfc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T08:41:57.063381Z",
     "iopub.status.busy": "2023-12-28T08:41:57.063047Z",
     "iopub.status.idle": "2023-12-28T08:41:58.745638Z",
     "shell.execute_reply": "2023-12-28T08:41:58.744934Z",
     "shell.execute_reply.started": "2023-12-28T08:41:57.063358Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torchcp in /usr/local/lib/python3.8/site-packages (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchcp\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as trn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "from torchcp.classification.predictors import ClusterPredictor, ClassWisePredictor, SplitPredictor\n",
    "from torchcp.classification.scores import THR, APS, SAPS, RAPS\n",
    "from torchcp.classification import Metrics\n",
    "from torchcp.utils import fix_randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5906099d-82df-4dfc-8144-ab792cd3ddc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T08:20:44.735964Z",
     "iopub.status.busy": "2023-12-28T08:20:44.735622Z",
     "iopub.status.idle": "2023-12-28T08:21:28.356837Z",
     "shell.execute_reply": "2023-12-28T08:21:28.355356Z",
     "shell.execute_reply.started": "2023-12-28T08:20:44.735943Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /output/.torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|██████████| 171M/171M [00:07<00:00, 22.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:12<00:00, 13269293.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/data/cifar-10-python.tar.gz to /root/data\n",
      "Experiment--Data : CIFAR-10, Model : ResNet101, Score : THR, Predictor : Standard, Alpha : 0.1\n",
      "The size of calibration set is 5000.\n",
      "Testing examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:10<00:00,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etestuating prediction sets...\n",
      "Coverage_rate: 0.8788.\n",
      "Average_size: 911.9408.\n",
      "CovGap: 9.948091821157124.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 手动设置命令行参数\n",
    "class Args:\n",
    "    def __init__(self, seed, alpha, predictor, score, penalty, kreg, weight, split):\n",
    "        self.seed = seed\n",
    "        self.alpha = alpha\n",
    "        self.predictor = predictor\n",
    "        self.score = score\n",
    "        self.penalty = penalty\n",
    "        self.kreg = kreg\n",
    "        self.weight = weight\n",
    "        self.split = split\n",
    "\n",
    "args = Args(seed=0, alpha=0.1, predictor=\"Standard\", score=\"THR\", penalty=1, kreg=0, weight=0.2, split=\"random\")\n",
    "\n",
    "fix_randomness(seed=args.seed)\n",
    "\n",
    "model_name = 'ResNet101'\n",
    "\n",
    "# load model\n",
    "model = torchvision.models.resnet101(weights=\"IMAGENET1K_V1\", progress=True)\n",
    "model_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(model_device)\n",
    "\n",
    "# load dataset (Using CIFAR-10)\n",
    "transform = trn.Compose([trn.Resize(256),\n",
    "                         trn.CenterCrop(224),\n",
    "                         trn.ToTensor(),\n",
    "                         trn.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                       std=[0.229, 0.224, 0.225])\n",
    "                         ])\n",
    "dataset = torchvision.datasets.CIFAR10(root=os.path.join(os.path.expanduser('~'), \"data\"), train=False, download=True, transform=transform)\n",
    "\n",
    "cal_dataset, test_dataset = torch.utils.data.random_split(dataset, [5000, 5000])  # 根据需要调整划分\n",
    "cal_data_loader = torch.utils.data.DataLoader(cal_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "\n",
    "alpha = args.alpha\n",
    "print(f\"Experiment--Data : CIFAR-10, Model : {model_name}, Score : {args.score}, Predictor : {args.predictor}, Alpha : {alpha}\")\n",
    "\n",
    "num_classes = 1000\n",
    "if args.score == \"THR\":\n",
    "    score_function = THR()\n",
    "elif args.score == \"APS\":\n",
    "    score_function = APS()\n",
    "elif args.score == \"RAPS\":\n",
    "    score_function = RAPS(args.penalty, args.kreg)\n",
    "elif args.score == \"SAPS\":\n",
    "    score_function = SAPS(weight=args.weight)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.predictor == \"Standard\":\n",
    "    predictor = SplitPredictor(score_function, model)\n",
    "elif args.predictor == \"ClassWise\":\n",
    "    predictor = ClassWisePredictor(score_function, model)\n",
    "elif args.predictor == \"Cluster\":\n",
    "    predictor = ClusterPredictor(score_function, model, args.seed)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "print(f\"The size of calibration set is {len(cal_dataset)}.\")\n",
    "predictor.calibrate(cal_data_loader, alpha)\n",
    "# predictor.evaluate(test_data_loader)\n",
    "\n",
    "# test examples\n",
    "print(\"Testing examples...\")\n",
    "prediction_sets = []\n",
    "labels_list = []\n",
    "with torch.no_grad():\n",
    "    for examples in tqdm(test_data_loader):\n",
    "        tmp_x, tmp_label = examples[0], examples[1]\n",
    "        prediction_sets_batch = predictor.predict(tmp_x)\n",
    "        prediction_sets.extend(prediction_sets_batch)\n",
    "        labels_list.append(tmp_label)\n",
    "test_labels = torch.cat(labels_list)\n",
    "\n",
    "metrics = Metrics()\n",
    "print(\"Etestuating prediction sets...\")\n",
    "print(f\"Coverage_rate: {metrics('coverage_rate')(prediction_sets, test_labels)}.\")\n",
    "print(f\"Average_size: {metrics('average_size')(prediction_sets, test_labels)}.\")\n",
    "print(f\"CovGap: {metrics('CovGap')(prediction_sets, test_labels, alpha, num_classes)}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742f10b5-31b7-40af-a188-57ae65746ca0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T08:33:03.965714Z",
     "iopub.status.busy": "2023-12-28T08:33:03.965451Z",
     "iopub.status.idle": "2023-12-28T08:33:21.158666Z",
     "shell.execute_reply": "2023-12-28T08:33:21.158135Z",
     "shell.execute_reply.started": "2023-12-28T08:33:03.965694Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Experiment--Data : CIFAR-100, Model : ResNet101, Score : THR, Predictor : Standard, Alpha : 0.1\n",
      "The size of calibration set is 5000.\n",
      "Testing examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:09<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating prediction sets...\n",
      "Coverage_rate: 0.8914.\n",
      "Average_size: 922.2136.\n",
      "CovGap: 10.340776907910568.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 手动设置命令行参数\n",
    "class Args:\n",
    "    def __init__(self, seed, alpha, predictor, score, penalty, kreg, weight, split):\n",
    "        self.seed = seed\n",
    "        self.alpha = alpha\n",
    "        self.predictor = predictor\n",
    "        self.score = score\n",
    "        self.penalty = penalty\n",
    "        self.kreg = kreg\n",
    "        self.weight = weight\n",
    "        self.split = split\n",
    "\n",
    "args = Args(seed=0, alpha=0.1, predictor=\"Standard\", score=\"THR\", penalty=1, kreg=0, weight=0.2, split=\"random\")\n",
    "\n",
    "fix_randomness(seed=args.seed)\n",
    "\n",
    "model_name = 'ResNet101'\n",
    "\n",
    "# load model\n",
    "model = torchvision.models.resnet101(weights=\"IMAGENET1K_V1\", progress=True)\n",
    "model_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(model_device)\n",
    "\n",
    "# load dataset (Using CIFAR-100)\n",
    "transform = trn.Compose([trn.Resize(256),\n",
    "                         trn.CenterCrop(224),\n",
    "                         trn.ToTensor(),\n",
    "                         trn.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                       std=[0.229, 0.224, 0.225])\n",
    "                         ])\n",
    "dataset = torchvision.datasets.CIFAR100(root=os.path.join(os.path.expanduser('~'), \"data\"), train=False, download=True, transform=transform)\n",
    "\n",
    "cal_dataset, test_dataset = torch.utils.data.random_split(dataset, [5000, 5000])  # 根据需要调整划分\n",
    "cal_data_loader = torch.utils.data.DataLoader(cal_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "\n",
    "alpha = args.alpha\n",
    "print(f\"Experiment--Data : CIFAR-100, Model : {model_name}, Score : {args.score}, Predictor : {args.predictor}, Alpha : {alpha}\")\n",
    "\n",
    "num_classes = 100\n",
    "if args.score == \"THR\":\n",
    "    score_function = THR()\n",
    "elif args.score == \"APS\":\n",
    "    score_function = APS()\n",
    "elif args.score == \"RAPS\":\n",
    "    score_function = RAPS(args.penalty, args.kreg)\n",
    "elif args.score == \"SAPS\":\n",
    "    score_function = SAPS(weight=args.weight)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.predictor == \"Standard\":\n",
    "    predictor = SplitPredictor(score_function, model)\n",
    "elif args.predictor == \"ClassWise\":\n",
    "    predictor = ClassWisePredictor(score_function, model)\n",
    "elif args.predictor == \"Cluster\":\n",
    "    predictor = ClusterPredictor(score_function, model, args.seed)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "print(f\"The size of calibration set is {len(cal_dataset)}.\")\n",
    "predictor.calibrate(cal_data_loader, alpha)\n",
    "\n",
    "# test examples\n",
    "print(\"Testing examples...\")\n",
    "prediction_sets = []\n",
    "labels_list = []\n",
    "with torch.no_grad():\n",
    "    for examples in tqdm(test_data_loader):\n",
    "        tmp_x, tmp_label = examples[0], examples[1]\n",
    "        prediction_sets_batch = predictor.predict(tmp_x)\n",
    "        prediction_sets.extend(prediction_sets_batch)\n",
    "        labels_list.append(tmp_label)\n",
    "test_labels = torch.cat(labels_list)\n",
    "\n",
    "metrics = Metrics()\n",
    "print(\"Evaluating prediction sets...\")\n",
    "print(f\"Coverage_rate: {metrics('coverage_rate')(prediction_sets, test_labels)}.\")\n",
    "print(f\"Average_size: {metrics('average_size')(prediction_sets, test_labels)}.\")\n",
    "print(f\"CovGap: {metrics('CovGap')(prediction_sets, test_labels, alpha, num_classes)}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c85162e-0273-4009-bf1c-f60809b331cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T08:37:43.598206Z",
     "iopub.status.busy": "2023-12-28T08:37:43.597935Z",
     "iopub.status.idle": "2023-12-28T08:37:59.612621Z",
     "shell.execute_reply": "2023-12-28T08:37:59.612132Z",
     "shell.execute_reply.started": "2023-12-28T08:37:43.598186Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment--Data : MNIST, Model : ResNet101, Score : THR, Predictor : Standard, Alpha : 0.1\n",
      "The size of calibration set is 5000.\n",
      "Testing examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:09<00:00,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating prediction sets...\n",
      "Coverage_rate: 0.9032.\n",
      "Average_size: 942.0134.\n",
      "CovGap: 10.83743783916796.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 手动设置命令行参数\n",
    "class Args:\n",
    "    def __init__(self, seed, alpha, predictor, score, penalty, kreg, weight, split):\n",
    "        self.seed = seed\n",
    "        self.alpha = alpha\n",
    "        self.predictor = predictor\n",
    "        self.score = score\n",
    "        self.penalty = penalty\n",
    "        self.kreg = kreg\n",
    "        self.weight = weight\n",
    "        self.split = split\n",
    "\n",
    "args = Args(seed=0, alpha=0.1, predictor=\"Standard\", score=\"THR\", penalty=1, kreg=0, weight=0.2, split=\"random\")\n",
    "\n",
    "fix_randomness(seed=args.seed)\n",
    "\n",
    "model_name = 'ResNet101'\n",
    "\n",
    "# load model\n",
    "model = torchvision.models.resnet101(weights=\"IMAGENET1K_V1\", progress=True)\n",
    "model_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(model_device)\n",
    "\n",
    "# load dataset (Using MNIST)\n",
    "transform = trn.Compose([trn.Resize(256),\n",
    "                         trn.CenterCrop(224),\n",
    "                         trn.Grayscale(num_output_channels=3),  # 将单通道图像变为三通道\n",
    "                         trn.ToTensor(),\n",
    "                         trn.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                       std=[0.229, 0.224, 0.225])\n",
    "                         ])\n",
    "# 使用MNIST\n",
    "dataset = torchvision.datasets.MNIST(root=os.path.join(os.path.expanduser('~'), \"data\"), train=False, download=True, transform=transform)\n",
    "\n",
    "cal_dataset, test_dataset = torch.utils.data.random_split(dataset, [5000, 5000])  # 根据需要调整划分\n",
    "cal_data_loader = torch.utils.data.DataLoader(cal_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "\n",
    "alpha = args.alpha\n",
    "print(f\"Experiment--Data : MNIST, Model : {model_name}, Score : {args.score}, Predictor : {args.predictor}, Alpha : {alpha}\")\n",
    "\n",
    "num_classes = 10\n",
    "if args.score == \"THR\":\n",
    "    score_function = THR()\n",
    "elif args.score == \"APS\":\n",
    "    score_function = APS()\n",
    "elif args.score == \"RAPS\":\n",
    "    score_function = RAPS(args.penalty, args.kreg)\n",
    "elif args.score == \"SAPS\":\n",
    "    score_function = SAPS(weight=args.weight)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.predictor == \"Standard\":\n",
    "    predictor = SplitPredictor(score_function, model)\n",
    "elif args.predictor == \"ClassWise\":\n",
    "    predictor = ClassWisePredictor(score_function, model)\n",
    "elif args.predictor == \"Cluster\":\n",
    "    predictor = ClusterPredictor(score_function, model, args.seed)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "print(f\"The size of calibration set is {len(cal_dataset)}.\")\n",
    "predictor.calibrate(cal_data_loader, alpha)\n",
    "\n",
    "# test examples\n",
    "print(\"Testing examples...\")\n",
    "prediction_sets = []\n",
    "labels_list = []\n",
    "with torch.no_grad():\n",
    "    for examples in tqdm(test_data_loader):\n",
    "        tmp_x, tmp_label = examples[0], examples[1]\n",
    "        prediction_sets_batch = predictor.predict(tmp_x)\n",
    "        prediction_sets.extend(prediction_sets_batch)\n",
    "        labels_list.append(tmp_label)\n",
    "test_labels = torch.cat(labels_list)\n",
    "\n",
    "metrics = Metrics()\n",
    "print(\"Evaluating prediction sets...\")\n",
    "print(f\"Coverage_rate: {metrics('coverage_rate')(prediction_sets, test_labels)}.\")\n",
    "print(f\"Average_size: {metrics('average_size')(prediction_sets, test_labels)}.\")\n",
    "print(f\"CovGap: {metrics('CovGap')(prediction_sets, test_labels, alpha, num_classes)}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd675b55-3b1c-4459-a234-3b244f9fc238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T08:38:52.667919Z",
     "iopub.status.busy": "2023-12-28T08:38:52.666420Z",
     "iopub.status.idle": "2023-12-28T08:39:16.505108Z",
     "shell.execute_reply": "2023-12-28T08:39:16.504422Z",
     "shell.execute_reply.started": "2023-12-28T08:38:52.667854Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:02<00:00, 10401737.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 174264.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 3117826.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 17918902.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/data/FashionMNIST/raw\n",
      "\n",
      "Experiment--Data : FashionMNIST, Model : ResNet101, Score : THR, Predictor : Standard, Alpha : 0.1\n",
      "The size of calibration set is 5000.\n",
      "Testing examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:09<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating prediction sets...\n",
      "Coverage_rate: 0.7498.\n",
      "Average_size: 894.687.\n",
      "CovGap: 20.33783188070897.\n"
     ]
    }
   ],
   "source": [
    "# 手动设置命令行参数\n",
    "class Args:\n",
    "    def __init__(self, seed, alpha, predictor, score, penalty, kreg, weight, split):\n",
    "        self.seed = seed\n",
    "        self.alpha = alpha\n",
    "        self.predictor = predictor\n",
    "        self.score = score\n",
    "        self.penalty = penalty\n",
    "        self.kreg = kreg\n",
    "        self.weight = weight\n",
    "        self.split = split\n",
    "\n",
    "args = Args(seed=0, alpha=0.1, predictor=\"Standard\", score=\"THR\", penalty=1, kreg=0, weight=0.2, split=\"random\")\n",
    "\n",
    "fix_randomness(seed=args.seed)\n",
    "\n",
    "model_name = 'ResNet101'\n",
    "\n",
    "# load model\n",
    "model = torchvision.models.resnet101(weights=\"IMAGENET1K_V1\", progress=True)\n",
    "model_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(model_device)\n",
    "\n",
    "# load dataset (Using FashionMNIST)\n",
    "transform = trn.Compose([trn.Resize(256),\n",
    "                         trn.CenterCrop(224),\n",
    "                         trn.Grayscale(num_output_channels=3),  # 将单通道图像变为三通道\n",
    "                         trn.ToTensor(),\n",
    "                         trn.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                       std=[0.229, 0.224, 0.225])\n",
    "                         ])\n",
    "# 使用FashionMNIST\n",
    "dataset = torchvision.datasets.FashionMNIST(root=os.path.join(os.path.expanduser('~'), \"data\"), train=False, download=True, transform=transform)\n",
    "\n",
    "cal_dataset, test_dataset = torch.utils.data.random_split(dataset, [5000, 5000])  # 根据需要调整划分\n",
    "cal_data_loader = torch.utils.data.DataLoader(cal_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "\n",
    "alpha = args.alpha\n",
    "print(f\"Experiment--Data : FashionMNIST, Model : {model_name}, Score : {args.score}, Predictor : {args.predictor}, Alpha : {alpha}\")\n",
    "\n",
    "num_classes = 10\n",
    "if args.score == \"THR\":\n",
    "    score_function = THR()\n",
    "elif args.score == \"APS\":\n",
    "    score_function = APS()\n",
    "elif args.score == \"RAPS\":\n",
    "    score_function = RAPS(args.penalty, args.kreg)\n",
    "elif args.score == \"SAPS\":\n",
    "    score_function = SAPS(weight=args.weight)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.predictor == \"Standard\":\n",
    "    predictor = SplitPredictor(score_function, model)\n",
    "elif args.predictor == \"ClassWise\":\n",
    "    predictor = ClassWisePredictor(score_function, model)\n",
    "elif args.predictor == \"Cluster\":\n",
    "    predictor = ClusterPredictor(score_function, model, args.seed)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "print(f\"The size of calibration set is {len(cal_dataset)}.\")\n",
    "predictor.calibrate(cal_data_loader, alpha)\n",
    "\n",
    "# test examples\n",
    "print(\"Testing examples...\")\n",
    "prediction_sets = []\n",
    "labels_list = []\n",
    "with torch.no_grad():\n",
    "    for examples in tqdm(test_data_loader):\n",
    "        tmp_x, tmp_label = examples[0], examples[1]\n",
    "        prediction_sets_batch = predictor.predict(tmp_x)\n",
    "        prediction_sets.extend(prediction_sets_batch)\n",
    "        labels_list.append(tmp_label)\n",
    "test_labels = torch.cat(labels_list)\n",
    "\n",
    "metrics = Metrics()\n",
    "print(\"Evaluating prediction sets...\")\n",
    "print(f\"Coverage_rate: {metrics('coverage_rate')(prediction_sets, test_labels)}.\")\n",
    "print(f\"Average_size: {metrics('average_size')(prediction_sets, test_labels)}.\")\n",
    "print(f\"CovGap: {metrics('CovGap')(prediction_sets, test_labels, alpha, num_classes)}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "030410d8-59ea-4136-93f6-e163001450e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T08:42:00.635552Z",
     "iopub.status.busy": "2023-12-28T08:42:00.634460Z",
     "iopub.status.idle": "2023-12-28T08:42:49.694981Z",
     "shell.execute_reply": "2023-12-28T08:42:49.694183Z",
     "shell.execute_reply.started": "2023-12-28T08:42:00.635499Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /root/data/test_32x32.mat\n",
      "Experiment--Data : SVHN, Model : ResNet101, Score : THR, Predictor : Standard, Alpha : 0.1\n",
      "The size of calibration set is 13016.\n",
      "Testing examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [00:30<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating prediction sets...\n",
      "Coverage_rate: 0.8999692685925015.\n",
      "Average_size: 957.0096035648432.\n",
      "CovGap: 10.822547382309603.\n"
     ]
    }
   ],
   "source": [
    "# 手动设置命令行参数\n",
    "class Args:\n",
    "    def __init__(self, seed, alpha, predictor, score, penalty, kreg, weight, split):\n",
    "        self.seed = seed\n",
    "        self.alpha = alpha\n",
    "        self.predictor = predictor\n",
    "        self.score = score\n",
    "        self.penalty = penalty\n",
    "        self.kreg = kreg\n",
    "        self.weight = weight\n",
    "        self.split = split\n",
    "\n",
    "args = Args(seed=0, alpha=0.1, predictor=\"Standard\", score=\"THR\", penalty=1, kreg=0, weight=0.2, split=\"random\")\n",
    "\n",
    "fix_randomness(seed=args.seed)\n",
    "\n",
    "model_name = 'ResNet101'\n",
    "\n",
    "# load model\n",
    "model = torchvision.models.resnet101(weights=\"IMAGENET1K_V1\", progress=True)\n",
    "model_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(model_device)\n",
    "\n",
    "# load dataset (Using SVHN)\n",
    "transform = trn.Compose([trn.Resize(256),\n",
    "                         trn.CenterCrop(224),\n",
    "                         trn.ToTensor(),\n",
    "                         trn.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                       std=[0.229, 0.224, 0.225])\n",
    "                         ])\n",
    "# 使用SVHN\n",
    "dataset = torchvision.datasets.SVHN(root=os.path.join(os.path.expanduser('~'), \"data\"), split='test', download=True, transform=transform)\n",
    "\n",
    "# 根据比例划分数据集\n",
    "cal_ratio = 0.5\n",
    "cal_length = int(cal_ratio * len(dataset))\n",
    "test_length = len(dataset) - cal_length\n",
    "cal_dataset, test_dataset = random_split(dataset, [cal_length, test_length])\n",
    "\n",
    "cal_data_loader = torch.utils.data.DataLoader(cal_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "\n",
    "alpha = args.alpha\n",
    "print(f\"Experiment--Data : SVHN, Model : {model_name}, Score : {args.score}, Predictor : {args.predictor}, Alpha : {alpha}\")\n",
    "\n",
    "num_classes = 10\n",
    "if args.score == \"THR\":\n",
    "    score_function = THR()\n",
    "elif args.score == \"APS\":\n",
    "    score_function = APS()\n",
    "elif args.score == \"RAPS\":\n",
    "    score_function = RAPS(args.penalty, args.kreg)\n",
    "elif args.score == \"SAPS\":\n",
    "    score_function = SAPS(weight=args.weight)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.predictor == \"Standard\":\n",
    "    predictor = SplitPredictor(score_function, model)\n",
    "elif args.predictor == \"ClassWise\":\n",
    "    predictor = ClassWisePredictor(score_function, model)\n",
    "elif args.predictor == \"Cluster\":\n",
    "    predictor = ClusterPredictor(score_function, model, args.seed)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "print(f\"The size of calibration set is {len(cal_dataset)}.\")\n",
    "predictor.calibrate(cal_data_loader, alpha)\n",
    "\n",
    "# test examples\n",
    "print(\"Testing examples...\")\n",
    "prediction_sets = []\n",
    "labels_list = []\n",
    "with torch.no_grad():\n",
    "    for examples in tqdm(test_data_loader):\n",
    "        tmp_x, tmp_label = examples[0], examples[1]\n",
    "        prediction_sets_batch = predictor.predict(tmp_x)\n",
    "        prediction_sets.extend(prediction_sets_batch)\n",
    "        labels_list.append(tmp_label)\n",
    "test_labels = torch.cat(labels_list)\n",
    "\n",
    "metrics = Metrics()\n",
    "print(\"Evaluating prediction sets...\")\n",
    "print(f\"Coverage_rate: {metrics('coverage_rate')(prediction_sets, test_labels)}.\")\n",
    "print(f\"Average_size: {metrics('average_size')(prediction_sets, test_labels)}.\")\n",
    "print(f\"CovGap: {metrics('CovGap')(prediction_sets, test_labels, alpha, num_classes)}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484255c7-b1b6-4a73-aa02-a5efc6dbc3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
